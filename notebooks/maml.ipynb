{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from collections import OrderedDict\n",
    "from more_itertools import chunked\n",
    "\n",
    "n_shot = 1\n",
    "n_class = 10\n",
    "n_local_update = 5\n",
    "batch_size = n_class\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "class OmniglotNet(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super(OmniglotNet, self).__init__()\n",
    "        \n",
    "        self.h=64\n",
    "        self.conv1 = nn.Conv2d(1, self.h, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(self.h, self.h, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(self.h, self.h, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm2d(self.h, momentum=1, affine=True)\n",
    "        self.bn2 = nn.BatchNorm2d(self.h, momentum=1, affine=True)\n",
    "        selfa.bn3 = nn.BatchNorm2d(self.h, momentum=1, affine=True)\n",
    "        self.fc = nn.Linear(self.h, n_class)\n",
    "        \n",
    "        # init is very very important!!!\n",
    "        # no init version -> HASH:ef56239\n",
    "        init.xavier_normal_(self.conv1.weight)\n",
    "        init.constant_(self.conv1.bias, 0)\n",
    "        init.xavier_normal_(self.conv2.weight)\n",
    "        init.constant_(self.conv2.bias, 0)\n",
    "        init.xavier_normal_(self.conv3.weight)\n",
    "        init.constant_(self.conv3.bias, 0)\n",
    "        \n",
    "        init.constant_(self.bn1.weight, 1)\n",
    "        init.constant_(self.bn1.bias, 0)\n",
    "        init.constant_(self.bn2.weight, 1)\n",
    "        init.constant_(self.bn2.bias, 0)\n",
    "        init.constant_(self.bn3.weight, 1)\n",
    "        init.constant_(self.bn3.bias, 0)\n",
    "        \n",
    "        init.normal_(self.fc.weight, 0, 0.01)\n",
    "        init.constant_(self.fc.bias, 1) # not 0 but 1.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), 2)\n",
    "        x = F.max_pool2d(F.relu(self.bn2(self.conv2(x))), 2)\n",
    "        x = F.max_pool2d(F.relu(self.bn3(self.conv3(x))), 2)\n",
    "        x = x.view(x.size(0), self.h)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    # for MAML local optimization\n",
    "    def manual_forward(self, x, params):\n",
    "        \n",
    "        x = F.conv2d(x, params['conv1.weight'].to(device), params['conv1.bias'].to(device))\n",
    "        dumy = torch.ones(np.prod(np.array(x.data.size()[1]))).cuda()*999999999999999999 # momentnum=1\n",
    "        x = F.batch_norm(x, dumy, dumy, params['bn1.weight'], params['bn1.bias'], True, momentum=1)\n",
    "        x = F.max_pool2d(F.relu(x), 2)\n",
    "        \n",
    "        x = F.conv2d(x, params['conv2.weight'].to(device), params['conv2.bias'].to(device))\n",
    "        dumy = torch.ones(np.prod(np.array(x.data.size()[1]))).cuda()*999999999999999999 # momentnum=1\n",
    "        x = F.batch_norm(x, dumy, dumy, params['bn2.weight'], params['bn2.bias'], True, momentum=1)\n",
    "        x = F.max_pool2d(F.relu(x), 2)\n",
    "        \n",
    "        x = F.conv2d(x, params['conv3.weight'].to(device), params['conv3.bias'].to(device))\n",
    "        dumy = torch.ones(np.prod(np.array(x.data.size()[1]))).cuda()*999999999999999999 # momentnum=1\n",
    "        x = F.batch_norm(x, dumy, dumy, params['bn3.weight'], params['bn3.bias'], True, momentum=1)\n",
    "        x = F.max_pool2d(F.relu(x), 2)\n",
    "        \n",
    "        x = x.view(x.size(0), self.h)\n",
    "        x = F.linear(x, params['fc.weight'].to(device), params['fc.bias'].to(device))\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "def train(model, device, train_data_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    for data, target in train_data_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_acc += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    train_loss /= len(train_data_loader.dataset)\n",
    "    train_acc /= len(train_data_loader.dataset)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test(model, device, test_data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            \n",
    "            test_loss += loss\n",
    "            test_acc += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_data_loader.dataset)\n",
    "    test_acc /= len(test_data_loader.dataset)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AugmentedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniglotAugmentedDataset(Dataset):\n",
    "    def __init__(self, path_to_chars, train, train_indices, transform):\n",
    "\n",
    "        self.data = []\n",
    "        self.path = NotImplementedError\n",
    "        \n",
    "        for label_i, (path_to_label, train_index) in enumerate(zip(path_to_chars, train_indices)):\n",
    "            chars = np.array(sorted(os.listdir(path_to_label)))\n",
    "            if train:\n",
    "                chars = chars[train_index]\n",
    "            else:\n",
    "                test_index = list(set(np.arange(20)) - set(train_index)) # omniglot has 20 images per character\n",
    "                chars = chars[test_index]\n",
    "            for char in chars:\n",
    "                path_to_char = os.path.join(path_to_label, char)\n",
    "                image = io.imread(path_to_char)\n",
    "                label_i = np.array(label_i)\n",
    "                self.data.append([image, label_i])\n",
    "            \n",
    "        self.transform = transform\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.data[idx])\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample[0], sample[1]\n",
    "        image = image / 255\n",
    "        image = (image-0.92208)/0.25140\n",
    "        image = image.reshape([28,28, 1])\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = np.array(image, np.float32)\n",
    "\n",
    "        return [torch.from_numpy(image), torch.from_numpy(label)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AugmentDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_task_train_data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: tensor([1, 6, 5, 8, 7, 9, 2, 3, 0, 4])\n",
      "\n",
      "local_task_test_data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: tensor([4, 4, 1, 9, 7, 7, 9, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "train_indices = np.random.randint(20, size=(n_class, n_shot))\n",
    "\n",
    "path_to_chars = [\n",
    "    '../data/omniglot_mini/images_background/Early_Aramaic/character08',\n",
    "    '../data/omniglot_mini/images_background/N_Ko/character05',\n",
    "    '../data/omniglot_mini/images_background/Early_Aramaic/character01',\n",
    "    '../data/omniglot_mini/images_background/Balinese/character04',\n",
    "    '../data/omniglot_mini/images_background/Burmese_(Myanmar)/character21',\n",
    "    '../data/omniglot_mini/images_background/Balinese/character03',\n",
    "    '../data/omniglot_mini/images_background/Gujarati/character35',\n",
    "    '../data/omniglot_mini/images_background/Bengali/character10',\n",
    "    '../data/omniglot_mini/images_background/Burmese_(Myanmar)/character18',\n",
    "    '../data/omniglot_mini/images_background/Armenian/character17'\n",
    "]\n",
    "\n",
    "print(\"local_task_train_data\")\n",
    "local_task_train_data_loader = DataLoader(\n",
    "    OmniglotAugmentedDataset(path_to_chars,\n",
    "                    train=True,\n",
    "                    train_indices=train_indices,\n",
    "                    transform=transforms.Compose([\n",
    "                        ToTensor(),\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for data, target in local_task_train_data_loader: # only have one batch\n",
    "    plt.figure(figsize=(10,1))\n",
    "    for i, x in enumerate(data):\n",
    "        plt.subplot(1, batch_size, i+1); plt.imshow(x[0])\n",
    "    plt.show()\n",
    "    print(\"y_true:\", target)\n",
    "\n",
    "print(\"\\nlocal_task_test_data\")\n",
    "local_task_test_data_loader = DataLoader(\n",
    "    OmniglotAugmentedDataset(path_to_chars,\n",
    "                    train=False,\n",
    "                    train_indices=train_indices,\n",
    "                    transform=transforms.Compose([\n",
    "                        ToTensor(),\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for data, target in local_task_test_data_loader: # only have one batch\n",
    "    plt.figure(figsize=(10,1))\n",
    "    for i, x in enumerate(data):\n",
    "        plt.subplot(1, batch_size, i+1); plt.imshow(x[0])\n",
    "    plt.show()\n",
    "    print(\"y_true:\", target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taskset and TaskLoader classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Taskset(object):\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class TaskLoader(object):\n",
    "    def __init__(self, taskset, shuffle=True):\n",
    "        self.taskset = taskset\n",
    "        self.sample_iter = iter(np.random.permutation(np.arange(len(taskset))))\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        return self.taskset[next(self.sample_iter)]\n",
    "    def __len__(self):\n",
    "        return len(self.taskset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AugmentedTaskset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniglotAugmentedTaskset(Taskset):\n",
    "    def __init__(self, path_to_omniglot, n_class, n_shot, meta_train):\n",
    "        \n",
    "        if meta_train:\n",
    "            path_to_langs = os.path.join(path_to_omniglot, \"images_background/\")\n",
    "        else:\n",
    "            path_to_langs = os.path.join(path_to_omniglot, \"images_evaluation/\")\n",
    "            \n",
    "        chars = []\n",
    "        \n",
    "        for path_to_lang in os.listdir(path_to_langs):\n",
    "            path_to_chars = os.path.join(path_to_langs, path_to_lang)\n",
    "            for path_to_char in os.listdir(path_to_chars):\n",
    "                chars.append(os.path.join(path_to_chars, path_to_char)) \n",
    "        \n",
    "        random.shuffle(chars)\n",
    "        tasks = list(chunked(chars, n_class))[:-1] # drop_last\n",
    "        \n",
    "        self.tasks = tasks\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tasks)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        train_indices = np.random.randint(20, size=(n_class, n_shot))\n",
    "        return {\"train\":\n",
    "                DataLoader(\n",
    "                    OmniglotAugmentedDataset(self.tasks[idx],\n",
    "                                    train=True,\n",
    "                                    train_indices=train_indices,\n",
    "                                    transform=transforms.Compose([\n",
    "                                        ToTensor()\n",
    "                                    ])),\n",
    "                    batch_size=batch_size, shuffle=True), \n",
    "                \"test\":\n",
    "                DataLoader(\n",
    "                    OmniglotAugmentedDataset(self.tasks[idx],\n",
    "                                    train=False,\n",
    "                                    train_indices=train_indices,\n",
    "                                    transform=transforms.Compose([\n",
    "                                        ToTensor()\n",
    "                                    ])),\n",
    "                    batch_size=batch_size, shuffle=True),\n",
    "                \"task\": self.tasks[idx] \n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AugmentTaskLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "['../data/omniglot_mini/images_background/Bengali/character06', '../data/omniglot_mini/images_background/Cyrillic/character23', '../data/omniglot_mini/images_background/Tifinagh/character27', '../data/omniglot_mini/images_background/Asomtavruli_(Georgian)/character33', '../data/omniglot_mini/images_background/Japanese_(hiragana)/character10', '../data/omniglot_mini/images_background/Tagalog/character12', '../data/omniglot_mini/images_background/Balinese/character03', '../data/omniglot_mini/images_background/Futurama/character17', '../data/omniglot_mini/images_background/Cyrillic/character31', '../data/omniglot_mini/images_background/Gujarati/character36']\n",
      "train\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 8, 6, 7, 2, 5, 4, 0, 3, 1])\n",
      "test\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 8, 3, 5, 5, 1, 3, 0, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "meta_train_task_loader = TaskLoader(\n",
    "    OmniglotAugmentedTaskset(\"../data/omniglot_mini/\", meta_train=True, n_class=n_class, n_shot=n_shot)\n",
    ")\n",
    "\n",
    "print(len(meta_train_task_loader.taskset))\n",
    "\n",
    "for i, meta_train_task in enumerate(meta_train_task_loader):\n",
    "    print(meta_train_task[\"task\"])\n",
    "    print(\"train\")\n",
    "    local_task_train_data_loader = meta_train_task[\"train\"]\n",
    "    for data, target in local_task_train_data_loader:\n",
    "        plt.figure(figsize=(10,1))\n",
    "        for j, x in enumerate(data):\n",
    "            plt.subplot(1, batch_size, j+1); plt.imshow(x[0])\n",
    "        plt.show()\n",
    "        print(target)\n",
    "    print(\"test\")\n",
    "    local_task_test_data_loader = meta_train_task[\"test\"]\n",
    "    for data, target in local_task_test_data_loader:\n",
    "        plt.figure(figsize=(10,1))\n",
    "        for j, x in enumerate(data):\n",
    "            plt.subplot(1, batch_size, j+1); plt.imshow(x[0])\n",
    "        plt.show()\n",
    "        print(target)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaLearner(object):\n",
    "    def __init__(self):\n",
    "        self.lr = 0.1\n",
    "        self.momentum = 0.5\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.master_net = OmniglotNet(n_class).to(self.device)\n",
    "        self.master_opt = optim.Adam(self.master_net.parameters(), lr=0.001)\n",
    "        self.keys = self.master_net.state_dict().keys()\n",
    "    \n",
    "    def copy_params(self, from_net, to_net):\n",
    "        params = {k: v for k, v in from_net.state_dict().items() if k in self.keys}\n",
    "        to_net.load_state_dict(params, strict=False)\n",
    "    \n",
    "    def save(self, model_path):\n",
    "        torch.save(self.master_net.state_dict(), model_path)\n",
    "    \n",
    "    def load(self, model_path):\n",
    "        self.master_net.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    def meta_test(self):\n",
    "        \n",
    "        meta_test_task_loader = TaskLoader(\n",
    "            OmniglotAugmentedTaskset(\"../data/omniglot_mini/\", meta_train=False, n_class=n_class, n_shot=n_shot))\n",
    "\n",
    "        test_loss, test_acc = [], [] # For logging.\n",
    "        \n",
    "        sleep(0.5)\n",
    "        with tqdm(meta_test_task_loader, desc=\"Meta Test \", ncols=10) as _tqdm:\n",
    "            for meta_test_task in _tqdm:\n",
    "\n",
    "                # copy master model to new branch model\n",
    "                faster_net = OmniglotNet(n_class).to(self.device)\n",
    "                self.copy_params(self.master_net, faster_net)\n",
    "                faster_opt = optim.SGD(faster_net.parameters(), lr=self.lr, momentum=self.momentum)\n",
    "\n",
    "                # make local task data loader\n",
    "                local_task_train_data_loader = meta_test_task[\"train\"]\n",
    "                local_task_test_data_loader = meta_test_task[\"test\"]\n",
    "\n",
    "                # ----------------------------------------------------------------\n",
    "                # meta test task train\n",
    "                # ----------------------------------------------------------------\n",
    "\n",
    "                for epoch in range(n_local_update):\n",
    "                    _train_loss, _train_acc = train(\n",
    "                        faster_net, self.device, local_task_train_data_loader, faster_opt, epoch)\n",
    "                    _tqdm.set_postfix(OrderedDict(\n",
    "                        epoch=epoch+1, \n",
    "                        train_loss=\"{:.3f}\".format(_train_loss), \n",
    "                        train_acc=\"{:.3f}\".format(_train_acc)))\n",
    "                # ----------------------------------------------------------------\n",
    "                # meta test task test\n",
    "                # ----------------------------------------------------------------\n",
    "\n",
    "                _test_loss, _test_acc = test(faster_net, self.device, local_task_test_data_loader)\n",
    "                test_loss.append(_test_loss)\n",
    "                test_acc.append(_test_acc)\n",
    "        \n",
    "        return np.mean(test_loss), np.mean(test_acc)\n",
    "\n",
    "    \n",
    "    def meta_train(self):\n",
    "        \n",
    "        meta_train_task_loader = TaskLoader(\n",
    "            OmniglotAugmentedTaskset(\"../data/omniglot_mini/\", meta_train=True, n_class=n_class, n_shot=n_shot))\n",
    "    \n",
    "        meta_grads = []\n",
    "        \n",
    "        test_loss, test_acc = [], [] # For logging.\n",
    "        \n",
    "        sleep(0.5)\n",
    "        with tqdm(meta_train_task_loader, desc=\"Meta Train\", ncols=10) as _tqdm:\n",
    "            for meta_train_task in _tqdm:\n",
    "                \n",
    "                # copy master model to new branch model\n",
    "                faster_net = OmniglotNet(n_class).to(self.device)\n",
    "                faster_net.forward = NotImplementedError # goodbye!\n",
    "                self.copy_params(self.master_net, faster_net)\n",
    "\n",
    "                # faster_params = OrderedDict((name, param) for (name, param) in faster_net.named_parameters())\n",
    "                master_params = OrderedDict((name, param) for (name, param) in self.master_net.named_parameters())\n",
    "\n",
    "                # make local task data loader\n",
    "                local_task_train_data_loader = meta_train_task[\"train\"]\n",
    "                local_task_test_data_loader = meta_train_task[\"test\"]\n",
    "\n",
    "                # ----------------------------------------------------------------\n",
    "                # meta train task train\n",
    "                # ----------------------------------------------------------------\n",
    "\n",
    "                first_train_for_this_task = True\n",
    "\n",
    "                for epoch in range(n_local_update):\n",
    "                    \n",
    "                    _train_loss = 0 # For tqdm.\n",
    "                    _train_acc = 0 # For tqdm.\n",
    "                    \n",
    "                    for data, target in local_task_train_data_loader:\n",
    "                        data, target = data.to(self.device), target.to(self.device)\n",
    "\n",
    "                        if first_train_for_this_task:\n",
    "                            # manual predict\n",
    "                            output = self.master_net(data)\n",
    "                            loss = F.nll_loss(output, target)\n",
    "                            pred = output.max(1, keepdim=True)[1]\n",
    "                            \n",
    "                            _train_loss += loss\n",
    "                            _train_acc += pred.eq(target.view_as(pred)).sum().item()\n",
    "                            \n",
    "                            grads = torch.autograd.grad(loss, self.master_net.parameters(), create_graph=True)\n",
    "\n",
    "                            faster_params = OrderedDict(\n",
    "                                (name, param - self.lr*grad)\n",
    "                                for ((name, param), grad) in zip(master_params.items(), grads)\n",
    "\n",
    "                            first_train_for_this_task = False\n",
    "\n",
    "                        else:\n",
    "                            # manual predict\n",
    "                            output = faster_net.manual_forward(data, faster_params)\n",
    "                            loss = F.nll_loss(output, target)\n",
    "                            pred = output.max(1, keepdim=True)[1]\n",
    "                            \n",
    "                            _train_loss += loss\n",
    "                            _train_acc += pred.eq(target.view_as(pred)).sum().item()\n",
    "                                                        \n",
    "                            grads = torch.autograd.grad(loss, faster_params.values(), create_graph=True)\n",
    "\n",
    "                            faster_params = OrderedDict(\n",
    "                                (name, param - self.lr*grad)\n",
    "                                for ((name, param), grad) in zip(faster_params.items(), grads)\n",
    "\n",
    "                        # manual optimize!!!\n",
    "                        faster_params = OrderedDict(\n",
    "                            (name, param - self.lr*grad)\n",
    "                            for ((name, param), grad) in zip(faster_params.items(), grads)\n",
    "                        )\n",
    "                    \n",
    "                    _train_loss /= len(local_task_train_data_loader.dataset)\n",
    "                    _train_acc /= len(local_task_train_data_loader.dataset)\n",
    "                    \n",
    "                    _tqdm.set_postfix(OrderedDict(\n",
    "                        epoch=epoch+1, \n",
    "                        train_loss=\"{:.3f}\".format(_train_loss), \n",
    "                        train_acc=\"{:.3f}\".format(_train_acc)))\n",
    "                \n",
    "                # ----------------------------------------------------------------\n",
    "                # meta train task test\n",
    "                # ----------------------------------------------------------------\n",
    "                \n",
    "                _test_loss = 0 # For logging.\n",
    "                _test_acc = 0 # For logging.\n",
    "                \n",
    "                for data, target in local_task_test_data_loader:\n",
    "                    data, target = data.to(self.device), target.to(self.device)\n",
    "\n",
    "                    output = faster_net.manual_forward(data, faster_params)\n",
    "                    loss = F.nll_loss(output, target) # test_loss計算するとこまではfaster_net\n",
    "\n",
    "                    # differentiates test_loss by master_net params\n",
    "                    grads = torch.autograd.grad(loss, self.master_net.parameters(), retain_graph=True)\n",
    "                    grads = {name:g for ((name, _), g) in zip(faster_net.named_parameters(), grads)}\n",
    "                    meta_grads.append(grads)\n",
    "\n",
    "                    pred = output.max(1, keepdim=True)[1]\n",
    "                    acc = pred.eq(target.view_as(pred)).sum()\n",
    "                    \n",
    "                    _test_loss += loss.item()\n",
    "                    _test_acc += acc.item()\n",
    "                \n",
    "                _test_loss /= len(local_task_test_data_loader.dataset)\n",
    "                _test_acc /= len(local_task_test_data_loader.dataset)  \n",
    "                test_loss.append(_test_loss)\n",
    "                test_acc.append(_test_acc)\n",
    "        \n",
    "        # ----------------------------------------------------------------\n",
    "        # end all tasks\n",
    "        # ----------------------------------------------------------------\n",
    "        \n",
    "        # ----------------------------------------------------------------\n",
    "        # meta update\n",
    "        # ----------------------------------------------------------------\n",
    "        \n",
    "        meta_grads = {k: sum(grads[k] for grads in meta_grads) for k in meta_grads[0].keys()}\n",
    "        \n",
    "        # using data,target from somewhere\n",
    "        dumy_output = self.master_net(data)\n",
    "        dumy_loss = F.nll_loss(dumy_output, target)\n",
    "        \n",
    "        # after dumy_loss.backward, rewrite grads\n",
    "        self.master_opt.zero_grad()\n",
    "        dumy_loss.backward(retain_graph=True)\n",
    "\n",
    "        hooks = []\n",
    "        for (k,v) in self.master_net.named_parameters():\n",
    "            def get_closure():\n",
    "                key = k\n",
    "                def replace_grad(grad):\n",
    "                    return meta_grads[key]\n",
    "                return replace_grad\n",
    "            hooks.append(v.register_hook(get_closure()))\n",
    "\n",
    "        # Compute grads for current step, replace with summed gradients as defined by hook\n",
    "        self.master_opt.zero_grad()\n",
    "        dumy_loss.backward()\n",
    "\n",
    "        # Update the net parameters with the accumulated gradient according to optimizer\n",
    "        self.master_opt.step()\n",
    "\n",
    "        # Remove the hooks before next training phase\n",
    "        for h in hooks:\n",
    "            h.remove()\n",
    "\n",
    "        return np.mean(test_loss), np.mean(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Test : 100%|█| 65/65 [00:03<00:00, 18.13it/s, epoch=5, train_loss=0.052, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0  (meta-test-task) test_loss: 1.856325, test_acc: 0.443158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [00:53<00:00,  1.81it/s, epoch=5, train_loss=0.103, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:03<00:00, 18.17it/s, epoch=5, train_loss=0.052, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1 (meta-train-task) test_loss: 0.196651, test_acc: 0.473246\n",
      "# 1  (meta-test-task) test_loss: 1.805581, test_acc: 0.469555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [00:53<00:00,  1.79it/s, epoch=5, train_loss=0.102, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:03<00:00, 18.20it/s, epoch=5, train_loss=0.060, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 2 (meta-train-task) test_loss: 0.190288, test_acc: 0.514200\n",
      "# 2  (meta-test-task) test_loss: 1.751450, test_acc: 0.510445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [00:54<00:00,  1.77it/s, epoch=5, train_loss=0.103, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:03<00:00, 18.65it/s, epoch=5, train_loss=0.065, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 3 (meta-train-task) test_loss: 0.185200, test_acc: 0.529989\n",
      "# 3  (meta-test-task) test_loss: 1.720231, test_acc: 0.510607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [00:54<00:00,  1.77it/s, epoch=5, train_loss=0.102, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:03<00:00, 18.30it/s, epoch=5, train_loss=0.053, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 4 (meta-train-task) test_loss: 0.179813, test_acc: 0.545395\n",
      "# 4  (meta-test-task) test_loss: 1.684454, test_acc: 0.522915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [00:54<00:00,  1.77it/s, epoch=5, train_loss=0.106, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:03<00:00, 18.92it/s, epoch=5, train_loss=0.071, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 5 (meta-train-task) test_loss: 0.178800, test_acc: 0.538816\n",
      "# 5  (meta-test-task) test_loss: 1.656486, test_acc: 0.521538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [00:53<00:00,  1.81it/s, epoch=5, train_loss=0.103, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:03<00:00, 18.70it/s, epoch=5, train_loss=0.076, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 6 (meta-train-task) test_loss: 0.175457, test_acc: 0.556140\n",
      "# 6  (meta-test-task) test_loss: 1.650850, test_acc: 0.522996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [00:53<00:00,  1.80it/s, epoch=5, train_loss=0.105, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:03<00:00, 18.95it/s, epoch=5, train_loss=0.063, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 7 (meta-train-task) test_loss: 0.173087, test_acc: 0.562281\n",
      "# 7  (meta-test-task) test_loss: 1.629652, test_acc: 0.532632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [00:53<00:00,  1.80it/s, epoch=5, train_loss=0.094, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:03<00:00, 19.08it/s, epoch=5, train_loss=0.063, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 8 (meta-train-task) test_loss: 0.171742, test_acc: 0.563596\n",
      "# 8  (meta-test-task) test_loss: 1.591447, test_acc: 0.553198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [00:52<00:00,  1.81it/s, epoch=5, train_loss=0.100, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:03<00:00, 19.03it/s, epoch=5, train_loss=0.051, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 9 (meta-train-task) test_loss: 0.169880, test_acc: 0.578399\n",
      "# 9  (meta-test-task) test_loss: 1.570865, test_acc: 0.558704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [00:53<00:00,  1.80it/s, epoch=5, train_loss=0.094, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:03<00:00, 18.90it/s, epoch=5, train_loss=0.061, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 10 (meta-train-task) test_loss: 0.169299, test_acc: 0.574616\n",
      "# 10  (meta-test-task) test_loss: 1.531101, test_acc: 0.587773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [00:52<00:00,  1.82it/s, epoch=5, train_loss=0.096, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:03<00:00, 19.37it/s, epoch=5, train_loss=0.055, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 11 (meta-train-task) test_loss: 0.167134, test_acc: 0.590954\n",
      "# 11  (meta-test-task) test_loss: 1.507207, test_acc: 0.593441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [00:53<00:00,  1.81it/s, epoch=5, train_loss=0.094, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:03<00:00, 18.59it/s, epoch=5, train_loss=0.052, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 12 (meta-train-task) test_loss: 0.163552, test_acc: 0.623739\n",
      "# 12  (meta-test-task) test_loss: 1.494844, test_acc: 0.600486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [00:52<00:00,  1.82it/s, epoch=5, train_loss=0.099, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:03<00:00, 19.07it/s, epoch=5, train_loss=0.052, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 13 (meta-train-task) test_loss: 0.163287, test_acc: 0.623629\n",
      "# 13  (meta-test-task) test_loss: 1.466116, test_acc: 0.616437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [00:53<00:00,  1.78it/s, epoch=5, train_loss=0.083, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:03<00:00, 18.89it/s, epoch=5, train_loss=0.049, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 14 (meta-train-task) test_loss: 0.160354, test_acc: 0.633936\n",
      "# 14  (meta-test-task) test_loss: 1.444461, test_acc: 0.618219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [00:54<00:00,  1.76it/s, epoch=5, train_loss=0.092, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:03<00:00, 17.76it/s, epoch=5, train_loss=0.053, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 15 (meta-train-task) test_loss: 0.159105, test_acc: 0.648739\n",
      "# 15  (meta-test-task) test_loss: 1.441214, test_acc: 0.620810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train:   3%| | 3/96 [00:01<00:51,  1.80it/s, epoch=5, train_loss=0.099, train_acc=1.000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-59bdc9bc9782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-a72309fe767c>\u001b[0m in \u001b[0;36mmeta_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                     \u001b[0;31m# differentiates test_loss by master_net params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaster_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaster_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0mmeta_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    143\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    144\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         inputs, allow_unused)\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "meta_learner = MetaLearner()\n",
    "\n",
    "# see normal few-shot learning\n",
    "for _ in range(1):\n",
    "    test_loss, test_acc = meta_learner.meta_test()\n",
    "    print(\"# {}  (meta-test-task) test_loss: {:.6f}, test_acc: {:.6f}\".format(\n",
    "        0, test_loss, test_acc))\n",
    "\n",
    "for epoch in range(1000):\n",
    "    \n",
    "    train_loss, train_acc = meta_learner.meta_train()\n",
    "    test_loss, test_acc = meta_learner.meta_test()\n",
    "    \n",
    "    print(\"# {} (meta-train-task) test_loss: {:.6f}, test_acc: {:.6f}\".format(\n",
    "        epoch+1, train_loss, train_acc))    \n",
    "    print(\"# {}  (meta-test-task) test_loss: {:.6f}, test_acc: {:.6f}\".format(\n",
    "        epoch+1, test_loss, test_acc))\n",
    "    \n",
    "    model_path = \"../model/model-epoch_{:05}-train_loss_{:0.3f}-train_acc_{:0.3f}-test_loss_{:0.3f}-test_acc_{:0.3f}.pt\".format(\n",
    "        epoch, train_loss, train_acc, test_loss, test_acc)\n",
    "    \n",
    "    meta_learner.save(model_path)\n",
    "#     meta_learner.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
